from cmath import exp
import numpy as np
import gym
import time
import random
import matplotlib.pyplot as plt

env = gym.make("CartPole-v0")
Q = np.zeros((10,10,10,10,2))
epsilon0 = 0.7
gamma = 0.95
alpha = 0.5
metrics = {'ep': [], 'avg': [], 'min': [], 'max': []}  # 

def choose_action(state,epsilon):
    
    if(random.random() < epsilon):
        
        action = env.action_space.sample()
        
    else:
        action = np.argmax(Q[state])
        
    return action    

def perform_action(action):
    new_state,reward,done,info = env.step(action)
    new_state = discretize(new_state)
    return new_state,reward,done
    
def update_Q(state,action,reward):
    
    
    (a,b,c,d) = state
    Q_max = np.max(Q[a,b,c,d])
    print(Q_max)
    print(Q[a,b,c,d][action])
    
    Q[a,b,c,d][action] = Q[a,b,c,d][action] + alpha*(reward+gamma*(Q_max)- Q[a,b,c,d][action])
    
    
    

def discretize(state):
    
    state[1] = int(10*(state[1] - env.observation_space.low[1])/(env.observation_space.high[1] - env.observation_space.low[1]))
    state[3] = int(10*(state[3] - env.observation_space.low[3])/(env.observation_space.high[3] - env.observation_space.low[3]))
    state[0] = int(10*(state[0] + 2.4)/(4.8))
    state[2] = int(10*(state[2] + 0.5)/(1))
    
    return state.astype('int32')

for i in range(100000):
    state = env.reset()
    state = discretize(state)
    done = False
    epsilon = epsilon0*(2.5**(-1*0.001*i))
    reward_sum = 0
    while(not done):
        action = choose_action(tuple(state),epsilon)
        new_state,reward,done = perform_action(action)
        update_Q(new_state,action,reward)
        env.render()
        reward_sum = reward_sum + reward
    
    
env.close()


